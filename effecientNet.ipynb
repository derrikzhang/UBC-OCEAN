{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install timm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcHPcxuPQiMc",
        "outputId": "926c9ec8-549d-4b98-e251-7e5a3109a1f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.9.12-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.16.0+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.19.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.66.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.23.5)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.9.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3NHTRNeQpgj",
        "outputId": "3b3d2faa-1cd7-49a0-f8ac-50529bc39def"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.2.1-py3-none-any.whl (806 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.1/806.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.23.5)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.2)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.1.0+cu118)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.10.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.10.0 torchmetrics-1.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VubyI-sPfSJ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import timm\n",
        "import torchmetrics\n",
        "import copy\n",
        "import torch.nn.functional as F\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiYEQuG-Pnfh",
        "outputId": "5579c781-6a4f-4ef4-8786-bd8c0582020d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Dt1pZxfPyAC",
        "outputId": "b1f13969-fd12-46ee-fc77-4dedc139fe1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ROOT_DIR = '/content/drive/MyDrive/Colab Notebooks/CS640/train_images_png'\n",
        "TEST_DIR = '/content/drive/MyDrive/Colab Notebooks/CS640/test_images_png'"
      ],
      "metadata": {
        "id": "6sTerBRsPywt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/CS640/train.csv\")\n",
        "df[\"image_id\"] = df[\"image_id\"].apply(lambda x: f\"{ROOT_DIR}/{x}.png\")\n",
        "\n",
        "# Label encoding\n",
        "label_encoder = LabelEncoder()\n",
        "df['label'] = label_encoder.fit_transform(df['label'])"
      ],
      "metadata": {
        "id": "buHViOYyP0fP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Dataset\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.dataframe.iloc[idx]['image_id']\n",
        "        label = self.dataframe.iloc[idx]['label']\n",
        "        image = cv2.imread(img_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=image)\n",
        "            image = augmented['image']\n",
        "\n",
        "        return image, label\n"
      ],
      "metadata": {
        "id": "5y2558TvP6qd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transforms\n",
        "transform = A.Compose([\n",
        "    A.Resize(224, 224),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "# Dataloaders\n",
        "train_dataset = CustomDataset(df, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2, pin_memory=True)\n"
      ],
      "metadata": {
        "id": "4gjQ71j0P9dJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UBCModel(nn.Module):\n",
        "    def __init__(self, model_name, num_classes, pretrained=True):\n",
        "        super(UBCModel, self).__init__()\n",
        "        self.model = timm.create_model(model_name, pretrained=pretrained, features_only=True)\n",
        "\n",
        "        # Use GeM Pooling\n",
        "        self.gem = GeM()\n",
        "\n",
        "        in_features = self.model.feature_info.channels()[-1]\n",
        "        self.fc = nn.Linear(in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)[-1]  # Get last stage feature map\n",
        "        x = self.gem(x)  # Apply GeM pooling\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        x = self.fc(x)  # Final fully connected layer\n",
        "        return x"
      ],
      "metadata": {
        "id": "c4KYxFTCP-F0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GeM(nn.Module):\n",
        "    def __init__(self, p=3, eps=1e-6):\n",
        "        super(GeM, self).__init__()\n",
        "        self.p = nn.Parameter(torch.ones(1) * p)\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.avg_pool2d(x.clamp(min=self.eps).pow(self.p), (x.size(-2), x.size(-1))).pow(1./self.p)\n"
      ],
      "metadata": {
        "id": "ir5fIHUhQAoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model, Optimizer, and Criterion\n",
        "model = UBCModel(\"tf_efficientnet_b0_ns\", num_classes=5)\n",
        "model.to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "WUX29nBiQDj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation data\n",
        "val_df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/CS640/test.csv\")\n",
        "val_df[\"image_id\"] = val_df[\"image_id\"].apply(lambda x: f\"{TEST_DIR}/{x}.png\")\n",
        "if 'label' in val_df.columns:\n",
        "    val_df['label'] = label_encoder.transform(val_df['label'])\n",
        "\n",
        "val_dataset = CustomDataset(val_df, transform=transform)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "tMHKJZFeQGOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and evaluation loops\n",
        "for epoch in range(40):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if i % 10 == 9:\n",
        "            print(f\"[{epoch + 1}, {i + 1}] loss: {running_loss / 5:.3f}\")\n",
        "            running_loss = 0.0\n",
        "\n",
        "print(\"Finished Training\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnwLEyFhQMdC",
        "outputId": "ce5c5ae6-161e-4bfb-e363-025de8e1530e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 10] loss: 4.307\n",
            "[2, 10] loss: 2.184\n",
            "[3, 10] loss: 1.494\n",
            "[4, 10] loss: 0.940\n",
            "[5, 10] loss: 0.724\n",
            "[6, 10] loss: 0.468\n",
            "[7, 10] loss: 0.362\n",
            "[8, 10] loss: 0.288\n",
            "[9, 10] loss: 0.197\n",
            "[10, 10] loss: 0.168\n",
            "[11, 10] loss: 0.140\n",
            "[12, 10] loss: 0.117\n",
            "[13, 10] loss: 0.088\n",
            "[14, 10] loss: 0.080\n",
            "[15, 10] loss: 0.072\n",
            "[16, 10] loss: 0.069\n",
            "[17, 10] loss: 0.054\n",
            "[18, 10] loss: 0.050\n",
            "[19, 10] loss: 0.049\n",
            "[20, 10] loss: 0.050\n",
            "[21, 10] loss: 0.042\n",
            "[22, 10] loss: 0.036\n",
            "[23, 10] loss: 0.032\n",
            "[24, 10] loss: 0.039\n",
            "[25, 10] loss: 0.032\n",
            "[26, 10] loss: 0.027\n",
            "[27, 10] loss: 0.028\n",
            "[28, 10] loss: 0.021\n",
            "[29, 10] loss: 0.021\n",
            "[30, 10] loss: 0.023\n",
            "[31, 10] loss: 0.016\n",
            "[32, 10] loss: 0.019\n",
            "[33, 10] loss: 0.015\n",
            "[34, 10] loss: 0.016\n",
            "[35, 10] loss: 0.014\n",
            "[36, 10] loss: 0.015\n",
            "[37, 10] loss: 0.011\n",
            "[38, 10] loss: 0.012\n",
            "[39, 10] loss: 0.019\n",
            "[40, 10] loss: 0.017\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
        "\n",
        "def evaluate_model(model, val_loader, device):\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
        "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
        "    report = classification_report(all_labels, all_preds)\n",
        "\n",
        "    return accuracy, f1, recall, precision, report\n",
        "\n",
        "accuracy, f1, recall, precision, report = evaluate_model(model, val_loader, device)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"F1 Score: {f1}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(\"\\nClassification Report:\\n\", report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2GjvaO2QQN_",
        "outputId": "be25dc96-55ac-4732-e3ef-1e6acd278029"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.4722222222222222\n",
            "F1 Score: 0.4722453291080742\n",
            "Recall: 0.4722222222222222\n",
            "Precision: 0.4757337838733188\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.38      0.45      0.41        20\n",
            "           1       0.42      0.44      0.43        25\n",
            "           2       0.65      0.62      0.64        45\n",
            "           3       0.11      0.11      0.11         9\n",
            "           4       0.33      0.22      0.27         9\n",
            "\n",
            "    accuracy                           0.47       108\n",
            "   macro avg       0.38      0.37      0.37       108\n",
            "weighted avg       0.48      0.47      0.47       108\n",
            "\n"
          ]
        }
      ]
    }
  ]
}